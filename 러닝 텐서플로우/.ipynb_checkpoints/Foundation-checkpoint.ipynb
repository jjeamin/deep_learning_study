{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 러닝 텐서플로우(Learning Tensorflow)\n",
    "구글에서 만든 오픈소스 프레임워크\n",
    "\n",
    "- 텐서 : 딥러닝에서 데이터를 표현하는 일반적인 방법\n",
    " + 다차원 배열\n",
    " + R,G,B (3차원 데이터)\n",
    " \n",
    " \n",
    "- 텐서플로우 : 텐서 + 플로우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello World!'\n"
     ]
    }
   ],
   "source": [
    "h = tf.constant(\"Hello\")\n",
    "w = tf.constant(\" World!\")\n",
    "hw = h + w\n",
    "\n",
    "with tf.Session() as sess: # sess = tf.Session()\n",
    "    ans = sess.run(hw) #출력 가능\n",
    "    \n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 소프트 맥스 회귀\n",
    "- softmax : 확률\n",
    " + 전부 합치면 1\n",
    " + x -> y(0~1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data\\train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data\\train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data\\t10k-labels-idx1-ubyte.gz\n",
      "Accuracy: 90.82%\n",
      "Accuracy: 91.56%\n",
      "Accuracy: 91.82%\n",
      "Accuracy: 91.82%\n",
      "Accuracy: 92.04%\n",
      "Accuracy: 92.08%\n",
      "Accuracy: 92.05%\n",
      "Accuracy: 92.22%\n",
      "Accuracy: 92.04%\n",
      "Accuracy: 92.16%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "DATA_DIR = '/tmp/data'\n",
    "NUM_STEPS = 1000\n",
    "MINIBATCH_SIZE = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "data = input_data.read_data_sets(DATA_DIR,one_hot=True)\n",
    "\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "\n",
    "y_true = tf.placeholder(tf.float32,[None,10])\n",
    "y_pred = tf.matmul(x,W)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_pred, labels=y_true))\n",
    "\n",
    "gd_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n",
    "\n",
    "correct_mask = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_mask,tf.float32))\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for _ in range(10):\n",
    "    for _ in range(NUM_STEPS):\n",
    "        batch_xs,batch_ys = data.train.next_batch(MINIBATCH_SIZE)\n",
    "        sess.run(gd_step,feed_dict={x:batch_xs, y_true:batch_ys})\n",
    "\n",
    "    rst = sess.run(accuracy,feed_dict={x:data.test.images,y_true:data.test.labels})\n",
    "\n",
    "    print(\"Accuracy: {:.4}%\".format(rst*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundation\n",
    "## 연산 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out = 5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.constant(5)\n",
    "b = tf.constant(2)\n",
    "c = tf.constant(3)\n",
    "\n",
    "d = tf.multiply(a,b)\n",
    "e = tf.add(c,b)\n",
    "f = tf.subtract(d,e)\n",
    "\n",
    "sess = tf.Session()\n",
    "out = sess.run(f)\n",
    "sess.close()\n",
    "print(\"out = {0}\".format(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그래프 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "g1 = tf.get_default_graph()\n",
    "g2 = tf.Graph()\n",
    "\n",
    "print(g1 is tf.get_default_graph())\n",
    "\n",
    "with g2.as_default():\n",
    "    print(g1 is tf.get_default_graph())\n",
    "\n",
    "print(g1 is tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 페치\n",
    "- 노드 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outs = [5, 2, 3, 10, 5, 5]\n",
      "<class 'numpy.int32'>\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    feches = [a,b,c,d,e,f]\n",
    "    outs = sess.run(feches)\n",
    "    \n",
    "print(\"outs = {}\".format(outs))\n",
    "print(type(outs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_50:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Const_51:0\", shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "c = tf.constant(3.0)\n",
    "print(c)\n",
    "\n",
    "c = tf.constant(3.0,dtype=tf.float64)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAST\n",
    "- 형변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'float32'>\n",
      "<dtype: 'int32'>\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([1,2,3],name = 'x',dtype = tf.float32)\n",
    "print(x.dtype)\n",
    "x = tf.cast(x,tf.int32) # 데이터 타입 새로 적용\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서\n",
    "- 1*1 = 스칼라\n",
    "- 1*N = 벡터\n",
    "- N*N = 행렬\n",
    "- N*N*N = 3차원 배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "(2, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "c = tf.constant([[1,2,3],[4,5,6]])\n",
    "print(c.shape)\n",
    "c = tf.constant(np.array([ \n",
    "                        [[1,2,3],\n",
    "                         [4,5,6]] , \n",
    "                        [[1,1,1],\n",
    "                         [2,2,2]] \n",
    "                        ]))\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. 3. 4.]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "c = tf.linspace(0.0,4.0,5)\n",
    "print(c.eval())\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "A = tf.constant([[1,2,3],[4,5,6]])\n",
    "print(A.shape)\n",
    "\n",
    "x = tf.constant([1,0,1])\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n",
      "[[ 4]\n",
      " [10]]\n"
     ]
    }
   ],
   "source": [
    "#행렬을 곱하려면 x를 변환시켜야한다\n",
    "x = tf.expand_dims(x,1)\n",
    "print(x.get_shape())\n",
    "\n",
    "b = tf.matmul(A,x)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "print(b.eval())\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이름\n",
    "```\n",
    "tf.constant(4,dtype = tf.float64,name='c')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:0\n",
      "c_1:0\n",
      "c_2:0\n",
      "c_3:0\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    c1 = tf.constant(4,dtype = tf.float64,name='c')\n",
    "    c2 = tf.constant(4,dtype = tf.int32,name='c')\n",
    "    c3 = tf.constant(4,dtype = tf.float64,name='c')\n",
    "    c4 = tf.constant(4,dtype = tf.int32,name='c')\n",
    "    \n",
    "print(c1.name)\n",
    "print(c2.name)\n",
    "print(c3.name)\n",
    "print(c4.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:0\n",
      "prefix_name/c:0\n",
      "prefix_name/c_1:0\n"
     ]
    }
   ],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default(): # as_default를 사용하면 해당 그래프가 기본 그래프인 콘텍스트 할당\n",
    "    c1 = tf.constant(4,dtype=tf.float64,name='c')\n",
    "    with tf.name_scope(\"prefix_name\"): # 그룹화\n",
    "        c2 = tf.constant(4,dtype=tf.int32,name='c')\n",
    "        c3 = tf.constant(4,dtype=tf.float64,name='c')\n",
    "print(c1.name)\n",
    "print(c2.name)\n",
    "print(c3.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 변수\n",
    "```\n",
    "tf.Variable()\n",
    "```\n",
    "- 변하는 수\n",
    "- 고정된 상태를 유지 할 수 있다. -> 변수의 현재 상태가 반복 과정 속에서의 상태에 영향을 줄 수 있기 때문이다.\n",
    "- 모델의 학습과정에서 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.1896572  -0.4299722  -0.46761578 -0.02529344 -1.7057981 ]]\n",
      "<tf.Variable 'var_18:0' shape=(1, 5) dtype=float32_ref>\n",
      "[[-0.00754655 -1.7255454   0.9521939  -0.2814501   0.97002816]]\n"
     ]
    }
   ],
   "source": [
    "init_val = tf.random_normal((1,5),0,1)\n",
    "sess = tf.Session()\n",
    "print(sess.run(init_val))\n",
    "var = tf.Variable(init_val, name='var') # 변수\n",
    "print(var)\n",
    "\n",
    "init = tf.global_variables_initializer() # 초기화 연산\n",
    "sess.run(init)\n",
    "\n",
    "print(sess.run(var))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "# 변수 초기화\n",
    "a = tf.Variable(5, name='my_variable_a')\n",
    " \n",
    "a = a.assign_add(a)\n",
    " \n",
    "init = tf.initialize_all_variables()\n",
    " \n",
    "sess = tf.Session()\n",
    " \n",
    "sess.run(init)\n",
    " \n",
    "print(sess.run(a))\n",
    "print(sess.run(a)) #변함\n",
    "print(sess.run(a)) #변함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 플레이스 홀더\n",
    "```\n",
    "tf.placehloder()\n",
    "```\n",
    "- 비어있는 변수\n",
    "- 입력데이터를 밀어넣는다.\n",
    "- 연산 및 입력에 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out = 0.5401109457015991\n"
     ]
    }
   ],
   "source": [
    "x_data = np.random.randn(5,10)\n",
    "y_data = np.random.randn(10,1)\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    x = tf.placeholder(tf.float32,shape=(5,10)) #5*10 공간\n",
    "    w = tf.placeholder(tf.float32,shape=(10,1)) #10*1 공간\n",
    "    b = tf.fill((5,1),-1.) #5*1 공간 -1 초기화\n",
    "    xw = tf.matmul(x,w)\n",
    "    xwb = xw + b\n",
    "    \n",
    "    s = tf.reduce_max(xwb) #최대값으로 줄인다(reduce)\n",
    "    with tf.Session() as sess:\n",
    "        out = sess.run(s,feed_dict={x:x_data,w:y_data})\n",
    "    print(\"out = {}\".format(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최적화\n",
    "\n",
    "> x = tf.placeholder(tf.float32,shape=[None,3]) <br>\n",
    "> y_true = tf.placeholder(tf.float32,shape=None) <br>\n",
    "> w = tf.Variable([[0,0,0]],dtype=tf.float32,name='weights') <br>\n",
    "> b = tf.Variable(0,dtype=tf.float32,name='bias')\n",
    "\n",
    "> y_pred = tf.matmul(w,tf.transpose(x)) + b \n",
    "- transpose = 전치함수\n",
    "\n",
    "### 손실함수 정의\n",
    "- 손실함수를 줄이는 것이 **우리의 목적**이다.\n",
    "- MSE(평균제곱오차)\n",
    "    + -> 실제값과 예측값 사이의 차이 제곱\n",
    "\n",
    "> loss = tf.reduce_mean(tf.square(y_true-y_pred))\n",
    "\n",
    "- **교차 엔트로피**(cross_entropy)\n",
    "    + -> 유사성\n",
    "\n",
    "> loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true,logits=y_pred) <br>\n",
    "> loss = tf.reduce_mean(loss)\n",
    "\n",
    "### 경사 하강법\n",
    "- 최솟값 수렴\n",
    "\n",
    "> optimizer = tf.train.GradientDescentOptimizer(learning_rate) <br>\n",
    "> train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_data = np.random.randn(2000,3)\n",
    "w_real = [0.3,0.5,0.1]\n",
    "b_real = -0.2\n",
    "\n",
    "noise = np.random.randn(1,2000) * 0.1\n",
    "y_data = np.matmul(w_real,x_data.T) + b_real + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선형 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [array([[0.23581381, 0.42544815, 0.08778735]], dtype=float32), -0.18028514]\n",
      "1 [array([[0.28574127, 0.48811623, 0.09964821]], dtype=float32), -0.20130846]\n",
      "2 [array([[0.29631522, 0.4976568 , 0.10058563]], dtype=float32), -0.20334913]\n",
      "3 [array([[0.2985782 , 0.49917218, 0.1004322 ]], dtype=float32), -0.20343208]\n",
      "4 [array([[0.29907048, 0.49942562, 0.10032216]], dtype=float32), -0.20339674]\n",
      "5 [array([[0.29917958, 0.49947053, 0.10028174]], dtype=float32), -0.2033807]\n",
      "6 [array([[0.29920426, 0.499479  , 0.10026936]], dtype=float32), -0.20337582]\n",
      "7 [array([[0.29920992, 0.4994807 , 0.10026588]], dtype=float32), -0.2033745]\n",
      "8 [array([[0.29921126, 0.49948105, 0.10026494]], dtype=float32), -0.20337416]\n",
      "9 [array([[0.29921156, 0.4994811 , 0.10026469]], dtype=float32), -0.20337409]\n",
      "10 [array([[0.29921165, 0.49948114, 0.10026463]], dtype=float32), -0.20337406]\n"
     ]
    }
   ],
   "source": [
    "NUM_STEP = 10\n",
    "\n",
    "g = tf.Graph()\n",
    "wb_ = []\n",
    "with g.as_default():\n",
    "    x = tf.placeholder(tf.float32,shape=[None,3])\n",
    "    y_true = tf.placeholder(tf.float32,shape=None)\n",
    "    \n",
    "    with tf.name_scope('inference') as scope:\n",
    "        w = tf.Variable([[0,0,0]],dtype=tf.float32,name='weight')\n",
    "        b = tf.Variable(0,dtype=tf.float32,name='bias')\n",
    "        y_pred = tf.matmul(w,tf.transpose(x)) + b\n",
    "        \n",
    "    with tf.name_scope('loss') as scope:\n",
    "        loss = tf.reduce_mean(tf.square(y_true-y_pred)) # square = 제곱\n",
    "        \n",
    "    with tf.name_scope('train') as scope:\n",
    "        learning_rate = 0.4\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "        train = optimizer.minimize(loss)\n",
    "        \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for step in range(NUM_STEP+1):\n",
    "            sess.run(train,{x:x_data,y_true:y_data})\n",
    "            print(step, sess.run([w,b]))\n",
    "            wb_.append(sess.run([w,b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 로지스틱 회귀\n",
    "- 시그모이드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20000\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1./(1+np.exp(-x))\n",
    "\n",
    "x_data = np.random.randn(N,3)\n",
    "w_real = [0.3,0.5,0.1]\n",
    "b_real = -0.2\n",
    "\n",
    "wxb = np.matmul(w_real,x_data.T) + b_real\n",
    "\n",
    "y_data_pre_noise = sigmoid(wxb)\n",
    "y_data = np.random.binomial(1,y_data_pre_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [array([[0.03300837, 0.05694366, 0.00933739]], dtype=float32), -0.02182497]\n",
      "5 [array([[0.14626522, 0.2521679 , 0.04147508]], dtype=float32), -0.09694247]\n",
      "10 [array([[0.2068761 , 0.35650367, 0.05875371]], dtype=float32), -0.13727812]\n",
      "15 [array([[0.24071355, 0.41468257, 0.06843163]], dtype=float32), -0.1598067]\n",
      "20 [array([[0.26014146, 0.4480508 , 0.07400179]], dtype=float32), -0.17272577]\n",
      "25 [array([[0.27148488, 0.46751493, 0.07726028]], dtype=float32), -0.18025354]\n",
      "30 [array([[0.27817377, 0.47898254, 0.07918473]], dtype=float32), -0.184682]\n",
      "35 [array([[0.28214106, 0.4857789 , 0.08032767]], dtype=float32), -0.18730222]\n",
      "40 [array([[0.2845022 , 0.48982093, 0.0810087 ]], dtype=float32), -0.18885799]\n",
      "45 [array([[0.28591028, 0.4922299 , 0.08141523]], dtype=float32), -0.18978372]\n",
      "50 [array([[0.28661558, 0.49343595, 0.08161904]], dtype=float32), -0.19024655]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "NUM_STEPS = 50\n",
    "\n",
    "\n",
    "g = tf.Graph()\n",
    "wb_ = []\n",
    "with g.as_default():\n",
    "    x = tf.placeholder(tf.float32,shape=[None,3])\n",
    "    y_true = tf.placeholder(tf.float32,shape=None)\n",
    "    \n",
    "    with tf.name_scope('inference') as scope:\n",
    "        w = tf.Variable([[0,0,0]],dtype=tf.float32,name='weights')\n",
    "        b = tf.Variable(0,dtype=tf.float32,name='bias')\n",
    "        y_pred = tf.matmul(w,tf.transpose(x)) + b\n",
    "\n",
    "    with tf.name_scope('loss') as scope:\n",
    "        loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true,logits=y_pred) \n",
    "        loss = tf.reduce_mean(loss)\n",
    "  \n",
    "    with tf.name_scope('train') as scope:\n",
    "        learning_rate = 0.5\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "        train = optimizer.minimize(loss)\n",
    "\n",
    "\n",
    "\n",
    "    # Before starting, initialize the variables.  We will 'run' this first.\n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)      \n",
    "        for step in range(NUM_STEPS):\n",
    "            sess.run(train,{x: x_data, y_true: y_data})\n",
    "            if (step % 5 == 0):\n",
    "                print(step, sess.run([w,b]))\n",
    "                wb_.append(sess.run([w,b]))\n",
    "\n",
    "        print(50, sess.run([w,b]))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35_64]",
   "language": "python",
   "name": "conda-env-py35_64-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
